<!DOCTYPE html>
<html>
<head>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <meta charset="utf-8">
  <meta name="description"
        content="Evaluating Copyright Takedown Methods for Language Models">
  <meta name="keywords" content="AI Safety, Model Alignment, Jailbreak">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Evaluating Copyright Takedown Methods for Language Models</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tifa.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Table Example</title>
  <style>
      table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid black;
        padding: 8px;
        text-align: left;
    }
    th {
        background-color: #f2f2f2;
    }
    .highlight {
        background-color: #d9fdd3;
    }
    .pbox {
        display: inline-block;
        width: 100%;
    }
    .bottom-border td {
        border-bottom: 2px solid black;
    }
  </style>
</head>
<body>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-BLEVG737MK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-BLEVG737MK');
  </script>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MFCT45H" height="0" width="0"
      style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->


<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
  

      <div class="navbar-item is-hoverable">
        <a class="navbar-item" href="#overview">
          Overview
        </a>
        <a class="navbar-item" href="#motivation">
          Motivation
        </a>
          <a class="navbar-item" href="#methods">
            Methods
          </a>
          <a class="navbar-item" href="#sparse">
            Sparsity Analysis
          </a>
          <a class="navbar-item" href="#overlap">
            Overlapping Analysis
          </a>
          <a class="navbar-item" href="#attack">
            FT-attack Results
          </a>
          <a class="navbar-item" href="#acknowledgement">
            Broader Impact and Acknowledgement
          </a>
          
          <a class="navbar-item" href="#reference">
            BibTeX
          </a>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Evaluating Copyright Takedown Methods<br>for Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://boyiwei.com">Boyi Wei<sup>*1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://swj0419.github.io/">Weijia Shi<sup>*2</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://hazelsuko07.github.io/yangsibo/">Yangsibo Huang<sup>*1</sup></a>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://nasmith.github.io/">Noah A. Smith<sup>2</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://pluskid.org/">Chiyuan Zhang</a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.washington.edu/people/faculty/lsz">Luke Zettlemoyer<sup>2</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.princeton.edu/~li/">Kai Li<sup>1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://www.peterhenderson.co">Peter Henderson<sup>1</sup></a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Princeton University, <sup>2</sup>University of Washington</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block" style="color: gray; font-size: smaller; font-style: italic;"><sup>*</sup>Equal contribution</span>
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.05162"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/boyiwei/CoTaEval"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/boyiwei/CoTaEval"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/spaces/boyiwei/CoTaEval_leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="far fa-chart-bar"></i>
                  </span>
                  <span>Leaderboard</span>
                  </a>
              </span>
            </div>        

          </div>
        </div>
        
      </div>
    </div>
  </div>
  
</section>






<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3", id="overview">Overview</h2>
      <div class="content has-text-justified">

        <p> Language models (LMs) derive their capabilities from extensive training on diverse data, including copyrighted material. 
          These models can memorize and generate content similar to their training data, potentially risking legal issues like copyright infringement. Therefore, model creators are motivated to develop mitigation methods that prevent generating particular copyrighted content, an ability we refer to as <span style="font-style: italic;" >copyright takedowns</span>. 
          However, there's lack of evaluation feasibility and side effects of these methods. In this project, we make the following key contributions:
          <ul>
            <li><span class="fontGrad-bg"><b>A taxonomy of infringement causes and takedown methods.</b></span> We identify two primary causes of infringement: <b>memorization</b> and <b>retrieval augmentation (RAG)</b>; and compile a taxonomy of takedown methods, including <b>generic prevention</b>, <b>decoding-time interventions</b>, and <b>training-based intervensions.</b></li>
            <li><span class="fontGrad-bg"><b>An evaluation suite.</b></span> We introduce <b>CoTaEval</b>, the first benchmark to evaluate the feasibility and side effects of takedown methods.</li>
            <li><span class="fontGrad-bg"><b>An evaluation of takedown methods and implications.</b></span> We evaluate the performace on various takedown methods, and find no method excel across all metrics, showing sinificant room for research in this unique problem setting and indicating potential unresolved challenges for live policy proposals.</li>

          </ul>
           
        </p>
        </div>
        <img src="./static/images/main.png" alt="pipeline">     
        </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- </section> -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3", id="motivation">Copyright Infringement in Language Models: Causes and Takedowns</h2>
      <div class="content has-text-justified">
          <p>
            <h4 class="title is-4", id="motivation">Causes</h4>
            Recent litigation (<a href="https://casetext.com/case/tremblay-v-openai-inc-2">Tremblay v. OpenAI, Inc</a>, <a href="https://casetext.com/case/kadrey-v-meta-platforms-inc">Kadrey v. Meta Platforms, Inc.</a>, <a href="https://www.courtlistener.com/docket/67778017/chabon-v-openai-inc/">Chabon v. OpenAI, Inc.</a>, <a href="https://www.courtlistener.com/docket/65669506/doe-1-v-github-inc/">DOE 1 v. GitHub, Inc.</a>) has pointed to two scenarios where a language model deployment might lead to infringement: 
            <ul>
              <li>Copyrighted content is memorized within the model's parameters during training (<i>Memorization</i>),
              <li>Copyrighted content is incorporated as additional context during retrieval-augmented generation (<i>RAG</i>).</li> 
            </ul>
            <h4 class="title is-4", id="motivation">Takedown methods</h4>
            Our evaluation considers three types of takedown methods that intervene at different stages of the language model:
            <ul>
              <li>Strategies that generally try to prevent infringement without specifying a blocklist, including System Prompt and Top-\(k\) Perturbation (Adding Gaussian noise to the logits in top-\(k\) sampling);</li>
              <li>Methods that prevent the generation of blocklisted content during decoding, including MemFree (<a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/642948/2/2023.inlg-main.3.pdf">Ippolito et al., 2023</a>), Reversed Context Aware Decoding (R-CAD; <a href="https://arxiv.org/pdf/2305.14739">Shi et al., 2023</a>);</li>
              <li>Training-based interventions like unlearning, including Gradient Ascent (<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797378&casa_token=sPm5CiNuBTQAAAAA:ORsczWa5cfRS2V-jt7eszNxl6Xu9Y9kVKKbPP3I6BU-8LY3CAAAGpL5ZbMhzxKSikC2MXAU">Thudi et al., 2022</a>), Gradient Difference(<a href="https://proceedings.mlr.press/v199/liu22a/liu22a.pdf">Liu et al., 2022</a>), KL minimization(<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Golatkar_Eternal_Sunshine_of_the_Spotless_Net_Selective_Forgetting_in_Deep_CVPR_2020_paper.pdf">Golatkar et al., 2020</a>),
              and Preference Optimization (<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/a85b405ed65c6477a4fe8302b5e06ce7-Paper-Conference.pdf">Rafailov et al., 2024</a>).</li>
            </ul>

          </p>
        </div>
      </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3", id="methods">The CoTaEval Evaluation Pipeline</h2>
      <div class="content has-text-justified">
          <p>
            Our evaluation focuses on two prevalent types of text often involved in copyright infringement cases: <i>news articles</i> and <i>books</i>. We divide the evaluation corpus into two parts: blocklisted content \(\mathcal{D}_{\text{blocklisted}}\), which the model should avoid generating, and in-domain content \(\mathcal{D}_{\text{in-domain}}\), which is from the same domain as \(\mathcal{D}_{\text{blocklisted}}\) but not subject to takedown requests. CoTaEval evalautes the takedown methods from three perspectives:
            <ul>
              <li><b>Infringement Risk Evaluation</b></li>
                  <ul>
                  <li>For <i>exact match</i> infringement, we evaluate: the length of character-level Longest Common Subsequence (LCS) \(\ell_{\mathsf{LCS}}^c\) between the generated text and the original text, and the length of word-level LCS \(\ell_{\mathsf{LCS}}^w\). </li>
                  <li>For <i>near duplicate</i> infringement, we evaluate: ROUGE-1, ROUGE-L (<a href="https://aclanthology.org/W04-1013.pdf">Lin, 2004</a>), the length of word level Accumulated Common Subsequences (ACS) \(\ell_{\mathsf{ACS}}^w\), Levenshtein distance \(\ell_{\mathsf{Lev}}\) (<a href="https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf">Levenshtein, 1966</a>), and MinHash Similarity \(\xi_{\mathsf{MH}}\) (<a href="https://www.misserpirat.dk/main/docs/00000004.pdf">Broder, 1997</a>).</li>
                  </ul>
              <li><b>Utility Evaluation</b>
                <ul>
                  <li>For <i>blocklisted utility and in-domain utility</i>, we compute word level F1 score between the generated content and answer for QA tasks in news articles, and compute ROUGE score between the generated content and ground truth for summarization taks in books.</li>
                  <li>For <i>general utility</i>, we use MT-Bench(<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf">Zheng et al., 2024</a>) and MMLU(<a href="https://arxiv.org/pdf/2009.03300">Hendrycks et al., 2021</a>), two widely adopted benchmarks that evaluate the model's knowledge and reasoning abilities across a diverse range of subjects and tasks. </li>
                </ul>
              <li><b>Efficiency Evaluation</b>
                <ul>
                  <li>We configure the model to generate 200 tokens and measure efficiency in terms of tokens per second. Using the value from the vanilla case as our baseline, we report the relative speed of each method by dividing its tokens per second by the tokens per second of the vanilla method.</li>
                </ul>
            </ul>
          </p>
          <table>
            <thead>
              <tr>
                  <th rowspan="2">Corpus</th>
                  <th rowspan="2">Original datapoint</th>
                  <th rowspan="2">Infringement Eval</th>
                  <th colspan="2">Utility Eval</th>
              </tr>
              <tr>
                  <th>Blocklisted or In-Domain</th>
                  <th>General</th>
              </tr>
          </thead>
          <tbody>
              <tr>
                  <td><b>News</b></td>
                  <td>Friends and colleagues of Apple founder Steve Jobs sent their condolences Wednesday after his death at the age of 56.</td>
                  <td>
                      <div><strong>Hint:</strong> Friends and colleagues of Apple founder</div>
                      <div><strong>Output:</strong> <span class="highlight">Steve Jobs sent their condolences Wednesday after he passed away.</span></div>
                  </td>
                  <td>
                      <div><strong>Question:</strong> Who is founder of Apple?</div>
                      <div><strong>Answer:</strong> Steve Jobs</div>
                  </td>
                  <td rowspan="2"><b>MMLU</b> & <b>MT-Bench</b></td>
              </tr>
              <tr >
                  <td><b>Books</b></td>
                  <td>Mrs Dursley had a sister called Lily Potter. She and her husband James Potter had a son called Harry Potter. They lived far from the Dursleys and did not speak to them much.</td>
                  <td>
                      <div><strong>Hint:</strong> Mrs Dursley had a sister</div>
                      <div><strong>Output:</strong> <span class="highlight">called Lily Potter. She and her husband James Potter had a son called Harry Potter. They lived far from the Dursleys and</span> rarely spoke to them.</div>
                  </td>
                  <td>
                      <div><strong>Question:</strong> Summarize this paragraph.</div>
                      <div><strong>Summary:</strong> Lily Potter and James Potter are Harry Potters' parents. They lived far from the Dursleys.</div>
                  </td>
              </tr>
              <tr class="bottom-border">
                <td colspan="5"></td>
            </tr>
          </tbody>
        </table>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3", id="sparse">Experiments</h2>
      <div class="content has-text-justified">
          <figure>
            <iframe src="./static/images/violin_plot_rag.html" width="100%" height="370"></iframe>
            <figcaption>(a) RAG setting</figcaption>
            <iframe src="./static/images/violin_plot_mem.html" width="100%" height="370"></iframe>
            <figcaption>(b) Memorization Setting</figcaption>
            <figcaption><span class="author-block" style="color: gray; font-size: smaller; font-style: italic;"><sup></sup>For the best experience, please view this interactive figure on a desktop.</span></figcaption>
          </figure>
          <p>
          The figures above shows 4 key metrics in evaluating infringement risk for Llama2-7B-chat model, under RAG setting and memorization setting. Below are three key observations:
          <ul>
            <li>System Prompt and MemFree offer some mitigation but cannot completely prevent infringement.</li>
            <li>Unlearning and Top-\(k\) perturbation reduce infringement but significantly compromises factual knowledge from the blocklisted content.</li>
            <li>R-CAD is effective for takedown but comes at the cost of efficiency and risk of utility drop.</li>
          </ul>
          </p>
        </div>
      </div>
  </div>
</section>




<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3", id="acknowledgement">Limitations and Acknowledgement</h2>
      
      <div class="content has-text-justified">
        <p>
          <b>Limitations.</b> CoTaEval is an initial effort to evaluate copyright takedown methods, there is room for improvement in future studies. For example, relatively small evaluation datasets, lack of evaluation of the offline cost, and the need for more diverse general utility evaluation. Furthermore, the field lacks a clear, quantitative definition of copyright
          infringement, as most cases need to be assessed on a case-by-case basis. Future work could focus on a more detailed
          exploration of legal standards for infringement.
        </p>
          <p>
          We express our gratitude to Tianle Cai, Andrew Sheinberg, and Mengzhou Xia for providing helpful feedback. Boyi Wei is supported by the Francis Robbins Upton Fellowship, and Yangsibo Huang is supported by the Wallace Memorial Fellowship.
          </p>
      </div>
    </div>
  </div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3", id="reference">BibTeX</h2>
      
      <div class="content has-text-justified">
    <p>If you find our code and paper helpful, please consider citing our work:
    </p>
    <pre><code>
</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We base the design of this website on <a href="https://nerfies.github.io/">https://nerfies.github.io</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
